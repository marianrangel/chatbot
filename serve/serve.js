// server.js
const express = require('express');
const cors = require('cors');
const axios = require('axios');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const dotenv = require('dotenv');

dotenv.config();

const app = express();
const PORT = process.env.PORT || 3001;

// ConfiguraÃ§Ã£o das APIs
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || "AIzaSyAHqN0QsXXpsbF2zYbALEjCbp7c05lv-6o");
const WEATHER_API_KEY = process.env.WEATHER_API_KEY || "sua_chave_da_openweathermap";

app.use(cors());
app.use(express.json());

// FunÃ§Ã£o para extrair nome da cidade da mensagem
const extractCityName = (message) => {
  // PadrÃµes comuns para identificar cidades
  const patterns = [
    /(?:em|na|no|para|de)\s+([A-ZÃ€-Ãša-zÃ -Ãº\s]+?)(?:\s+hoje|\?|$|\.)/i,
    /(?:clima|tempo|temperatura|previsÃ£o)\s+(?:para|em|na|no|de)\s+([A-ZÃ€-Ãša-zÃ -Ãº\s]+?)(?:\s+hoje|\?|$|\.)/i,
    /(?:como estÃ¡|vai estar)\s+(?:em|na|no)\s+([A-ZÃ€-Ãša-zÃ -Ãº\s]+?)(?:\s+hoje|\?|$|\.)/i
  ];
  
  for (const pattern of patterns) {
    const match = message.match(pattern);
    if (match && match[1]) {
      // Remove possÃ­veis preposiÃ§Ãµes no final
      return match[1].trim().replace(/\s+(em|na|no|de|para)$/, '');
    }
  }
  
  return "SÃ£o Paulo"; // Cidade padrÃ£o se nenhuma for identificada
};

// FunÃ§Ã£o para verificar se a mensagem contÃ©m perguntas sobre clima/tempo
const isWeatherQuestion = (message) => {
  const weatherRegex = /(clima|tempo|temperatura|chover|chuva|previsÃ£o|ensolarado|sol|vento|frio|calor|quente|graus|roupa|vestir)/i;
  const cityRegex = /(em|na|no|para|de)\s+([A-ZÃ€-Ãša-zÃ -Ãº\s]+)/i;
  const questionRegex = /(como|qual|que|estÃ¡|vai|pode|poderia|deve|vestir|usar)/i;
  
  return (
    (weatherRegex.test(message) && questionRegex.test(message)) ||
    message.includes("como estÃ¡ o tempo") ||
    message.includes("previsÃ£o do tempo") ||
    message.includes("vai chover") ||
    message.includes("temperatura") ||
    message.includes("que roupa usar")
  );
};

// FunÃ§Ã£o para recomendar roupas baseadas na temperatura
const getClothingRecommendation = (temp, conditions) => {
  if (temp < 10) {
    return "EstÃ¡ muito frio! Recomendo usar vÃ¡rias camadas de roupas, como camiseta, blusa, suÃ©ter e casaco pesado. NÃ£o esqueÃ§a de cachecol, luvas e gorro para se proteger do frio intenso.";
  } else if (temp < 15) {
    return "EstÃ¡ frio. VocÃª deve usar calÃ§as, um suÃ©ter ou moletom e um casaco mais leve. Uma echarpe ou cachecol tambÃ©m podem ser Ãºteis.";
  } else if (temp < 20) {
    return "A temperatura estÃ¡ amena. Uma calÃ§a jeans com uma camiseta de manga comprida e talvez um casaco leve ou cardigÃ£ deve ser suficiente.";
  } else if (temp < 25) {
    return "O clima estÃ¡ agradÃ¡vel. VocÃª pode usar calÃ§as leves ou atÃ© mesmo bermuda/saia, com camiseta. Leve um casaco leve para caso esfrie mais tarde.";
  } else if (temp < 30) {
    return "EstÃ¡ quente. Roupas leves como shorts/bermudas/saias, camisetas, vestidos leves sÃ£o ideais. Considere usar protetor solar e levar uma garrafa de Ã¡gua.";
  } else {
    return "EstÃ¡ muito quente! Vista-se com roupas bem leves, preferencialmente de algodÃ£o ou tecidos que permitam a transpiraÃ§Ã£o. Protetor solar Ã© essencial, assim como manter-se hidratado.";
  }
};

// Endpoint para obter informaÃ§Ãµes do clima
app.get('/api/weather', async (req, res) => {
  const { city } = req.query;
  
  if (!city) {
    return res.status(400).json({ error: 'Nome da cidade Ã© obrigatÃ³rio' });
  }
  
  try {
    const response = await axios.get(
      `https://api.openweathermap.org/data/2.5/weather`,
      {
        params: {
          q: city,
          appid: WEATHER_API_KEY,
          units: 'metric',
          lang: 'pt_br'
        }
      }
    );
    
    const weatherData = response.data;
    const temp = Math.round(weatherData.main.temp);
    const clothing = getClothingRecommendation(temp, weatherData.weather[0].main);
    
    res.json({
      city: weatherData.name,
      temperature: temp,
      tempMin: Math.round(weatherData.main.temp_min),
      tempMax: Math.round(weatherData.main.temp_max),
      humidity: weatherData.main.humidity,
      weatherDesc: weatherData.weather[0].description,
      clothing
    });
  } catch (error) {
    console.error('Erro ao buscar dados do clima:', error.response?.data || error.message);
    
    if (error.response?.status === 404) {
      res.status(404).json({ error: 'Cidade nÃ£o encontrada' });
    } else {
      res.status(500).json({ error: 'Erro ao buscar dados do clima' });
    }
  }
});

// Endpoint /chat
app.post('/chat', async (req, res) => {
  const mensagemUsuario = req.body.mensagem;
  const historicoRecebido = req.body.historico || [];

  try {
    // Verifica se Ã© uma pergunta sobre clima/tempo
    if (isWeatherQuestion(mensagemUsuario)) {
      const city = extractCityName(mensagemUsuario);
      
      try {
        const weatherResponse = await axios.get(
          `http://localhost:${PORT}/api/weather`,
          { params: { city } }
        );
        
        const weatherData = weatherResponse.data;
        const weatherText = `
ðŸŒ¡ï¸ Clima atual em ${weatherData.city}:
Temperatura: ${weatherData.temperature}Â°C (mÃ­nima: ${weatherData.tempMin}Â°C, mÃ¡xima: ${weatherData.tempMax}Â°C)
CondiÃ§Ã£o: ${weatherData.weatherDesc}
Umidade: ${weatherData.humidity}%

ðŸ‘• RecomendaÃ§Ã£o de vestuÃ¡rio:
${weatherData.clothing}
        `.trim();
        
        // Cria o novo histÃ³rico para enviar de volta
        const novoHistorico = [
          ...historicoRecebido,
          { role: "user", parts: [{ text: mensagemUsuario }] },
          { role: "model", parts: [{ text: weatherText }] }
        ];
        
        res.json({ resposta: weatherText, historico: novoHistorico });
      } catch (error) {
        // Se houver erro ao buscar clima, envia para o modelo de IA
        const model = genAI.getGenerativeModel({ model: "gemini-pro" });
        const chat = model.startChat({
          history: historicoRecebido,
          generationConfig: {
            temperature: 0.9,
            maxOutputTokens: 1024
          }
        });
        
        const result = await chat.sendMessage(mensagemUsuario);
        const response = await result.response;
        const textoResposta = response.text();
        
        const novoHistorico = [
          ...historicoRecebido,
          { role: "user", parts: [{ text: mensagemUsuario }] },
          { role: "model", parts: [{ text: textoResposta }] }
        ];
        
        res.json({ resposta: textoResposta, historico: novoHistorico });
      }
    } else {
      // Se nÃ£o for pergunta sobre clima, usa o modelo de IA diretamente
      const model = genAI.getGenerativeModel({ model: "gemini-pro" });
      const chat = model.startChat({
        history: historicoRecebido,
        generationConfig: {
          temperature: 0.9,
          maxOutputTokens: 1024
        },
        safetySettings: [
          { category: "HARM_CATEGORY_DEROGATORY", threshold: 3 },
          { category: "HARM_CATEGORY_VIOLENCE", threshold: 3 }
        ]
      });
      
      const result = await chat.sendMessage(mensagemUsuario);
      const response = await result.response;
      const textoResposta = response.text();
      
      const novoHistorico = [
        ...historicoRecebido,
        { role: "user", parts: [{ text: mensagemUsuario }] },
        { role: "model", parts: [{ text: textoResposta }] }
      ];
      
      res.json({ resposta: textoResposta, historico: novoHistorico });
    }
  } catch (error) {
    console.error("Erro ao processar mensagem:", error);
    res.status(500).json({ 
      erro: "Desculpe, nÃ£o consegui processar sua mensagem agora." 
    });
  }
});

// Inicia o servidor
app.listen(PORT, () => {
  console.log(`Servidor rodando em http://localhost:${PORT}`);
});